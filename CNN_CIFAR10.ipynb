{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_CIFAR10.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/Manasa9391/Cognitive-Computing/blob/master/CNN_CIFAR10.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "ImEH2iXGdfp9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The base code had an optimizer of RMSprop and the model is 59.7 percent accurate on testing. "
      ]
    },
    {
      "metadata": {
        "id": "JBNNE4K2dUkG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "8IuKPAxCaT2e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "outputId": "6fa7aa05-43f1-457e-8d2e-710c55f96095"
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "import os\n",
        "\n",
        "\n",
        "batch_size = 1024\n",
        "num_classes = 10\n",
        "epochs = 70\n",
        "data_augmentation = True\n",
        "num_predictions = 20\n",
        "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
        "model_name = 'keras_cifar10_trained_model.h5'\n",
        "\n",
        "\n",
        "\n",
        "# The data, split between train and test sets:\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# Convert class vectors to binary class matrices.\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), padding='same',\n",
        "                 input_shape=x_train.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "# initiate RMSprop optimizer\n",
        "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
        "\n",
        "# Let's train the model using RMSprop\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "\n",
        "\n",
        "def save_history(history, result_file):\n",
        "    loss = history.history['loss']\n",
        "    acc = history.history['acc']\n",
        "    val_loss = history.history['val_loss']\n",
        "    val_acc = history.history['val_acc']\n",
        "    nb_epoch = len(acc)\n",
        "\n",
        "    with open(result_file, \"w\") as fp:\n",
        "        fp.write(\"epoch\\tloss\\tacc\\tval_loss\\tval_acc\\n\")\n",
        "        for i in range(nb_epoch):\n",
        "            fp.write(\"%d\\t%f\\t%f\\t%f\\t%f\\n\" %\n",
        "                     (i, loss[i], acc[i], val_loss[i], val_acc[i]))\n",
        "            \n",
        "            \n",
        "        \n",
        "        \n",
        "\n",
        "if not data_augmentation:\n",
        "    print('Not using data augmentation.')\n",
        "    model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True)\n",
        "else:\n",
        "    print('Using real-time data augmentation.')\n",
        "    # This will do preprocessing and realtime data augmentation:\n",
        "    datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
        "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        # randomly shift images horizontally (fraction of total width)\n",
        "        width_shift_range=0.1,\n",
        "        # randomly shift images vertically (fraction of total height)\n",
        "        height_shift_range=0.1,\n",
        "        shear_range=0.,  # set range for random shear\n",
        "        zoom_range=0.,  # set range for random zoom\n",
        "        channel_shift_range=0.,  # set range for random channel shifts\n",
        "        # set mode for filling points outside the input boundaries\n",
        "        fill_mode='nearest',\n",
        "        cval=0.,  # value used for fill_mode = \"constant\"\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=False,  # randomly flip images\n",
        "        # set rescaling factor (applied before any other transformation)\n",
        "        rescale=None,\n",
        "        # set function that will be applied on each input\n",
        "        preprocessing_function=None,\n",
        "        # image data format, either \"channels_first\" or \"channels_last\"\n",
        "        data_format=None,\n",
        "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
        "        validation_split=0.0)\n",
        "\n",
        "    # Compute quantities required for feature-wise normalization\n",
        "    # (std, mean, and principal components if ZCA whitening is applied).\n",
        "    datagen.fit(x_train)\n",
        "    # Fit the model on the batches generated by datagen.flow().\n",
        "    history =model.fit_generator(datagen.flow(x_train, y_train,\n",
        "                                     batch_size=batch_size),\n",
        "                        epochs=epochs,\n",
        "                        validation_data=(x_test, y_test),\n",
        "                        workers=4)\n",
        "    save_history(history, 'history.txt')\n",
        "\n",
        "# Save model and weights\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "model_path = os.path.join(save_dir, model_name)\n",
        "model.save(model_path)\n",
        "print('Saved trained model at %s ' % model_path)\n",
        "\n",
        "# Score trained model.\n",
        "scores = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])\n",
        "scores_t = model.evaluate(x_train, y_train, verbose=1)\n",
        "print('Train loss:', scores_t[0])\n",
        "print('Train accuracy:', scores_t[1])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n",
            "Using real-time data augmentation.\n",
            "Epoch 1/10\n",
            "49/49 [==============================] - 33s 665ms/step - loss: 2.1557 - acc: 0.1959 - val_loss: 2.0118 - val_acc: 0.2809\n",
            "Epoch 2/10\n",
            "49/49 [==============================] - 31s 641ms/step - loss: 1.9676 - acc: 0.2823 - val_loss: 1.8430 - val_acc: 0.3538\n",
            "Epoch 3/10\n",
            "49/49 [==============================] - 31s 640ms/step - loss: 1.8673 - acc: 0.3246 - val_loss: 1.7608 - val_acc: 0.3780\n",
            "Epoch 4/10\n",
            "49/49 [==============================] - 32s 643ms/step - loss: 1.8123 - acc: 0.3471 - val_loss: 1.7067 - val_acc: 0.3897\n",
            "Epoch 5/10\n",
            "49/49 [==============================] - 31s 642ms/step - loss: 1.7762 - acc: 0.3577 - val_loss: 1.6715 - val_acc: 0.4059\n",
            "Epoch 6/10\n",
            "49/49 [==============================] - 32s 645ms/step - loss: 1.7476 - acc: 0.3696 - val_loss: 1.6543 - val_acc: 0.4100\n",
            "Epoch 7/10\n",
            "49/49 [==============================] - 32s 645ms/step - loss: 1.7197 - acc: 0.3757 - val_loss: 1.6096 - val_acc: 0.4239\n",
            "Epoch 8/10\n",
            "49/49 [==============================] - 31s 641ms/step - loss: 1.6975 - acc: 0.3847 - val_loss: 1.6181 - val_acc: 0.4152\n",
            "Epoch 9/10\n",
            "49/49 [==============================] - 32s 643ms/step - loss: 1.6728 - acc: 0.3936 - val_loss: 1.5485 - val_acc: 0.4446\n",
            "Epoch 10/10\n",
            "49/49 [==============================] - 31s 638ms/step - loss: 1.6523 - acc: 0.3990 - val_loss: 1.5352 - val_acc: 0.4462\n",
            "Saved trained model at /content/saved_models/keras_cifar10_trained_model.h5 \n",
            "10000/10000 [==============================] - 3s 308us/step\n",
            "Test loss: 1.5351509552001954\n",
            "Test accuracy: 0.4462\n",
            "50000/50000 [==============================] - 8s 160us/step\n",
            "Train loss: 1.5432152082061767\n",
            "Train accuracy: 0.44528\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fBehqG4KOYoI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#model.save(\"C:\\\\Users\\\\Manasa\\\\Desktop\\\\Srikanth Assignment\\\\cifar.h5\")\n",
        "\n",
        "model.save('model.h5')\n",
        "\n",
        "from google.colab import files\n",
        "files.download(\"model.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JplWBcjvSE1K",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.save_weights('C:\\\\Users\\\\Manasa\\Desktop\\\\Srikanth Assignment')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5izrpzyHV7gc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fjecl9JHP98l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "outputId": "2e31bcd1-08db-46c2-9808-70c52ec93d70"
      },
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "def convertCIFER10Data(image):\n",
        "    img = image.astype('float32')\n",
        "    img /= 255\n",
        "    c = np.zeros(32*32*3).reshape((1,32,32,3))\n",
        "    c[0] = img\n",
        "    return c\n",
        "  \n",
        "right = 0\n",
        "mistake = 0\n",
        "for i in range(11):\n",
        "    index = random.randint(0, x_test.shape[0])\n",
        "    image = x_test[index]\n",
        "    data = convertCIFER10Data(image)\n",
        "\n",
        "    ret = model.predict(data, batch_size=1) \n",
        "    print(ret)\n",
        "\n",
        "    bestnum = 0.0\n",
        "    bestclass = 0\n",
        "    for n in [0,1,2,3,4,5,6,7,8,9]:\n",
        "        if bestnum > ret[0][n]:\n",
        "            bestnum = ret[0][n]\n",
        "            bestclass = n\n",
        "    i = list(y_test[index]).index(1)\n",
        "    if i == bestclass:\n",
        "      right += 1\n",
        "    else:\n",
        "      mistake += 1\n",
        "                                                                   \n",
        "\n",
        "print(y_test[index])"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.06742913 0.04840138 0.16081674 0.10377883 0.17389461 0.09219659\n",
            "  0.16125782 0.09382654 0.0481891  0.05020925]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-4a3021adf691>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m#i = list(y_test[index]).index(1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mbestclass\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m       \u001b[0mright\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "SF17CNsSdVcb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Changing the Optimizer to Adam"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_z1E6MEMdG5T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2635
        },
        "outputId": "c2432111-93bc-4b5b-aa3e-50a02289a43f"
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "import os\n",
        "\n",
        "batch_size = 1024\n",
        "num_classes = 10\n",
        "epochs = 80\n",
        "data_augmentation = True\n",
        "num_predictions = 20\n",
        "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
        "model_name = 'keras_cifar10_trained_model.h5'\n",
        "\n",
        "# The data, split between train and test sets:\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# Convert class vectors to binary class matrices.\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), padding='same',\n",
        "                 input_shape=x_train.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "# initiate RMSprop optimizer\n",
        "#opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
        "opt = keras.optimizers.adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
        "\n",
        "# Let's train the model using RMSprop\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "if not data_augmentation:\n",
        "    print('Not using data augmentation.')\n",
        "    model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True)\n",
        "else:\n",
        "    print('Using real-time data augmentation.')\n",
        "    # This will do preprocessing and realtime data augmentation:\n",
        "    datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
        "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        # randomly shift images horizontally (fraction of total width)\n",
        "        width_shift_range=0.1,\n",
        "        # randomly shift images vertically (fraction of total height)\n",
        "        height_shift_range=0.1,\n",
        "        shear_range=0.,  # set range for random shear\n",
        "        zoom_range=0.,  # set range for random zoom\n",
        "        channel_shift_range=0.,  # set range for random channel shifts\n",
        "        # set mode for filling points outside the input boundaries\n",
        "        fill_mode='nearest',\n",
        "        cval=0.,  # value used for fill_mode = \"constant\"\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=False,  # randomly flip images\n",
        "        # set rescaling factor (applied before any other transformation)\n",
        "        rescale=None,\n",
        "        # set function that will be applied on each input\n",
        "        preprocessing_function=None,\n",
        "        # image data format, either \"channels_first\" or \"channels_last\"\n",
        "        data_format=None,\n",
        "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
        "        validation_split=0.0)\n",
        "\n",
        "    # Compute quantities required for feature-wise normalization\n",
        "    # (std, mean, and principal components if ZCA whitening is applied).\n",
        "    datagen.fit(x_train)\n",
        "\n",
        "    # Fit the model on the batches generated by datagen.flow().\n",
        "    history=model.fit_generator(datagen.flow(x_train, y_train,\n",
        "                                     batch_size=batch_size),\n",
        "                        epochs=epochs,\n",
        "                        validation_data=(x_test, y_test),\n",
        "                        workers=4)\n",
        "    save_history(history, 'history.txt')\n",
        "\n",
        "# Save model and weights\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "model_path = os.path.join(save_dir, model_name)\n",
        "model.save(model_path)\n",
        "print('Saved trained model at %s ' % model_path)\n",
        "\n",
        "# Score trained model.\n",
        "scores = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])\n",
        "scores_train = model.evaluate(x_train, y_train, verbose=1)\n",
        "print('Train loss:', scores_train[0])\n",
        "print('Train accuracy:', scores_train[1])"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 25s 0us/step\n",
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n",
            "Using real-time data augmentation.\n",
            "Epoch 1/70\n",
            "49/49 [==============================] - 38s 767ms/step - loss: 2.0196 - acc: 0.2541 - val_loss: 1.7184 - val_acc: 0.3890\n",
            "Epoch 2/70\n",
            "49/49 [==============================] - 34s 699ms/step - loss: 1.6794 - acc: 0.3903 - val_loss: 1.4401 - val_acc: 0.4771\n",
            "Epoch 3/70\n",
            "49/49 [==============================] - 35s 705ms/step - loss: 1.5196 - acc: 0.4467 - val_loss: 1.3223 - val_acc: 0.5195\n",
            "Epoch 4/70\n",
            "49/49 [==============================] - 35s 713ms/step - loss: 1.4283 - acc: 0.4852 - val_loss: 1.2567 - val_acc: 0.5462\n",
            "Epoch 5/70\n",
            "49/49 [==============================] - 35s 709ms/step - loss: 1.3495 - acc: 0.5147 - val_loss: 1.2142 - val_acc: 0.5615\n",
            "Epoch 6/70\n",
            "49/49 [==============================] - 35s 714ms/step - loss: 1.2968 - acc: 0.5338 - val_loss: 1.1840 - val_acc: 0.5820\n",
            "Epoch 7/70\n",
            "49/49 [==============================] - 34s 700ms/step - loss: 1.2506 - acc: 0.5518 - val_loss: 1.0691 - val_acc: 0.6184\n",
            "Epoch 8/70\n",
            "49/49 [==============================] - 34s 703ms/step - loss: 1.2008 - acc: 0.5718 - val_loss: 1.0253 - val_acc: 0.6387\n",
            "Epoch 9/70\n",
            "49/49 [==============================] - 34s 701ms/step - loss: 1.1662 - acc: 0.5839 - val_loss: 1.0713 - val_acc: 0.6158\n",
            "Epoch 10/70\n",
            "49/49 [==============================] - 35s 705ms/step - loss: 1.1391 - acc: 0.5949 - val_loss: 0.9869 - val_acc: 0.6540\n",
            "Epoch 11/70\n",
            "49/49 [==============================] - 34s 702ms/step - loss: 1.1071 - acc: 0.6059 - val_loss: 0.9716 - val_acc: 0.6619\n",
            "Epoch 12/70\n",
            "49/49 [==============================] - 34s 703ms/step - loss: 1.0765 - acc: 0.6178 - val_loss: 0.9384 - val_acc: 0.6737\n",
            "Epoch 13/70\n",
            "49/49 [==============================] - 34s 700ms/step - loss: 1.0473 - acc: 0.6306 - val_loss: 0.9297 - val_acc: 0.6730\n",
            "Epoch 14/70\n",
            "49/49 [==============================] - 34s 701ms/step - loss: 1.0203 - acc: 0.6384 - val_loss: 0.9019 - val_acc: 0.6852\n",
            "Epoch 15/70\n",
            "49/49 [==============================] - 35s 721ms/step - loss: 1.0005 - acc: 0.6478 - val_loss: 0.9340 - val_acc: 0.6766\n",
            "Epoch 16/70\n",
            "49/49 [==============================] - 35s 704ms/step - loss: 0.9829 - acc: 0.6533 - val_loss: 0.8787 - val_acc: 0.6942\n",
            "Epoch 17/70\n",
            "49/49 [==============================] - 35s 705ms/step - loss: 0.9584 - acc: 0.6645 - val_loss: 0.8356 - val_acc: 0.7117\n",
            "Epoch 18/70\n",
            "49/49 [==============================] - 34s 703ms/step - loss: 0.9345 - acc: 0.6693 - val_loss: 0.8004 - val_acc: 0.7259\n",
            "Epoch 19/70\n",
            "49/49 [==============================] - 35s 706ms/step - loss: 0.9256 - acc: 0.6728 - val_loss: 0.7911 - val_acc: 0.7288\n",
            "Epoch 20/70\n",
            "49/49 [==============================] - 35s 708ms/step - loss: 0.9184 - acc: 0.6787 - val_loss: 0.7814 - val_acc: 0.7325\n",
            "Epoch 21/70\n",
            "49/49 [==============================] - 35s 705ms/step - loss: 0.9000 - acc: 0.6822 - val_loss: 0.7983 - val_acc: 0.7244\n",
            "Epoch 22/70\n",
            "49/49 [==============================] - 35s 712ms/step - loss: 0.8694 - acc: 0.6940 - val_loss: 0.7282 - val_acc: 0.7516\n",
            "Epoch 23/70\n",
            "49/49 [==============================] - 35s 705ms/step - loss: 0.8644 - acc: 0.6971 - val_loss: 0.7239 - val_acc: 0.7473\n",
            "Epoch 24/70\n",
            "49/49 [==============================] - 35s 723ms/step - loss: 0.8539 - acc: 0.6997 - val_loss: 0.7700 - val_acc: 0.7343\n",
            "Epoch 25/70\n",
            "49/49 [==============================] - 34s 702ms/step - loss: 0.8388 - acc: 0.7061 - val_loss: 0.7144 - val_acc: 0.7547\n",
            "Epoch 26/70\n",
            "49/49 [==============================] - 34s 701ms/step - loss: 0.8359 - acc: 0.7047 - val_loss: 0.7245 - val_acc: 0.7495\n",
            "Epoch 27/70\n",
            "49/49 [==============================] - 34s 703ms/step - loss: 0.8195 - acc: 0.7129 - val_loss: 0.7487 - val_acc: 0.7413\n",
            "Epoch 28/70\n",
            "49/49 [==============================] - 35s 713ms/step - loss: 0.8056 - acc: 0.7169 - val_loss: 0.6895 - val_acc: 0.7603\n",
            "Epoch 29/70\n",
            "49/49 [==============================] - 35s 704ms/step - loss: 0.7925 - acc: 0.7211 - val_loss: 0.7211 - val_acc: 0.7535\n",
            "Epoch 30/70\n",
            "49/49 [==============================] - 34s 698ms/step - loss: 0.7963 - acc: 0.7212 - val_loss: 0.6930 - val_acc: 0.7626\n",
            "Epoch 31/70\n",
            "49/49 [==============================] - 34s 699ms/step - loss: 0.7770 - acc: 0.7274 - val_loss: 0.6599 - val_acc: 0.7715\n",
            "Epoch 32/70\n",
            "49/49 [==============================] - 34s 698ms/step - loss: 0.7659 - acc: 0.7308 - val_loss: 0.6856 - val_acc: 0.7658\n",
            "Epoch 33/70\n",
            "49/49 [==============================] - 35s 711ms/step - loss: 0.7606 - acc: 0.7335 - val_loss: 0.6361 - val_acc: 0.7796\n",
            "Epoch 34/70\n",
            "49/49 [==============================] - 34s 702ms/step - loss: 0.7524 - acc: 0.7374 - val_loss: 0.6609 - val_acc: 0.7728\n",
            "Epoch 35/70\n",
            "49/49 [==============================] - 35s 707ms/step - loss: 0.7463 - acc: 0.7398 - val_loss: 0.6756 - val_acc: 0.7697\n",
            "Epoch 36/70\n",
            "49/49 [==============================] - 34s 694ms/step - loss: 0.7442 - acc: 0.7395 - val_loss: 0.6365 - val_acc: 0.7793\n",
            "Epoch 37/70\n",
            "49/49 [==============================] - 34s 691ms/step - loss: 0.7303 - acc: 0.7451 - val_loss: 0.6512 - val_acc: 0.7754\n",
            "Epoch 38/70\n",
            "49/49 [==============================] - 34s 695ms/step - loss: 0.7319 - acc: 0.7441 - val_loss: 0.6452 - val_acc: 0.7789\n",
            "Epoch 39/70\n",
            "49/49 [==============================] - 34s 693ms/step - loss: 0.7242 - acc: 0.7474 - val_loss: 0.6020 - val_acc: 0.7949\n",
            "Epoch 40/70\n",
            "49/49 [==============================] - 34s 701ms/step - loss: 0.7120 - acc: 0.7508 - val_loss: 0.6477 - val_acc: 0.7761\n",
            "Epoch 41/70\n",
            "49/49 [==============================] - 34s 703ms/step - loss: 0.7122 - acc: 0.7497 - val_loss: 0.6121 - val_acc: 0.7894\n",
            "Epoch 42/70\n",
            "49/49 [==============================] - 35s 721ms/step - loss: 0.7033 - acc: 0.7537 - val_loss: 0.6434 - val_acc: 0.7809\n",
            "Epoch 43/70\n",
            "49/49 [==============================] - 34s 704ms/step - loss: 0.6970 - acc: 0.7562 - val_loss: 0.6327 - val_acc: 0.7811\n",
            "Epoch 44/70\n",
            "49/49 [==============================] - 35s 706ms/step - loss: 0.6897 - acc: 0.7586 - val_loss: 0.6270 - val_acc: 0.7826\n",
            "Epoch 45/70\n",
            "49/49 [==============================] - 34s 702ms/step - loss: 0.6888 - acc: 0.7586 - val_loss: 0.6244 - val_acc: 0.7884\n",
            "Epoch 46/70\n",
            "49/49 [==============================] - 35s 705ms/step - loss: 0.6797 - acc: 0.7646 - val_loss: 0.6084 - val_acc: 0.7928\n",
            "Epoch 47/70\n",
            "49/49 [==============================] - 34s 702ms/step - loss: 0.6844 - acc: 0.7597 - val_loss: 0.6237 - val_acc: 0.7866\n",
            "Epoch 48/70\n",
            "49/49 [==============================] - 35s 706ms/step - loss: 0.6763 - acc: 0.7639 - val_loss: 0.6436 - val_acc: 0.7795\n",
            "Epoch 49/70\n",
            "49/49 [==============================] - 35s 713ms/step - loss: 0.6654 - acc: 0.7664 - val_loss: 0.6115 - val_acc: 0.7910\n",
            "Epoch 50/70\n",
            "49/49 [==============================] - 35s 713ms/step - loss: 0.6573 - acc: 0.7672 - val_loss: 0.6162 - val_acc: 0.7889\n",
            "Epoch 51/70\n",
            "49/49 [==============================] - 35s 716ms/step - loss: 0.6585 - acc: 0.7712 - val_loss: 0.5802 - val_acc: 0.8033\n",
            "Epoch 52/70\n",
            "49/49 [==============================] - 35s 705ms/step - loss: 0.6576 - acc: 0.7701 - val_loss: 0.6032 - val_acc: 0.7935\n",
            "Epoch 53/70\n",
            "49/49 [==============================] - 35s 704ms/step - loss: 0.6542 - acc: 0.7705 - val_loss: 0.5831 - val_acc: 0.7990\n",
            "Epoch 54/70\n",
            "49/49 [==============================] - 35s 711ms/step - loss: 0.6515 - acc: 0.7722 - val_loss: 0.6003 - val_acc: 0.7960\n",
            "Epoch 55/70\n",
            "49/49 [==============================] - 35s 706ms/step - loss: 0.6418 - acc: 0.7759 - val_loss: 0.5778 - val_acc: 0.8016\n",
            "Epoch 56/70\n",
            "49/49 [==============================] - 35s 712ms/step - loss: 0.6423 - acc: 0.7764 - val_loss: 0.5637 - val_acc: 0.8076\n",
            "Epoch 57/70\n",
            "49/49 [==============================] - 35s 715ms/step - loss: 0.6327 - acc: 0.7796 - val_loss: 0.5834 - val_acc: 0.8015\n",
            "Epoch 58/70\n",
            "49/49 [==============================] - 35s 704ms/step - loss: 0.6311 - acc: 0.7792 - val_loss: 0.5593 - val_acc: 0.8100\n",
            "Epoch 59/70\n",
            "49/49 [==============================] - 35s 710ms/step - loss: 0.6383 - acc: 0.7796 - val_loss: 0.5769 - val_acc: 0.8041\n",
            "Epoch 60/70\n",
            "49/49 [==============================] - 36s 730ms/step - loss: 0.6244 - acc: 0.7828 - val_loss: 0.5915 - val_acc: 0.7955\n",
            "Epoch 61/70\n",
            "49/49 [==============================] - 34s 700ms/step - loss: 0.6225 - acc: 0.7822 - val_loss: 0.5579 - val_acc: 0.8081\n",
            "Epoch 62/70\n",
            "49/49 [==============================] - 34s 704ms/step - loss: 0.6203 - acc: 0.7835 - val_loss: 0.5608 - val_acc: 0.8120\n",
            "Epoch 63/70\n",
            "49/49 [==============================] - 35s 711ms/step - loss: 0.6193 - acc: 0.7833 - val_loss: 0.5853 - val_acc: 0.8013\n",
            "Epoch 64/70\n",
            "49/49 [==============================] - 35s 710ms/step - loss: 0.6169 - acc: 0.7855 - val_loss: 0.5717 - val_acc: 0.8057\n",
            "Epoch 65/70\n",
            "49/49 [==============================] - 35s 704ms/step - loss: 0.6090 - acc: 0.7863 - val_loss: 0.5539 - val_acc: 0.8091\n",
            "Epoch 66/70\n",
            "49/49 [==============================] - 35s 712ms/step - loss: 0.6122 - acc: 0.7857 - val_loss: 0.5539 - val_acc: 0.8083\n",
            "Epoch 67/70\n",
            "49/49 [==============================] - 35s 714ms/step - loss: 0.5985 - acc: 0.7931 - val_loss: 0.5355 - val_acc: 0.8159\n",
            "Epoch 68/70\n",
            "49/49 [==============================] - 34s 704ms/step - loss: 0.5994 - acc: 0.7917 - val_loss: 0.5737 - val_acc: 0.8046\n",
            "Epoch 69/70\n",
            "49/49 [==============================] - 36s 728ms/step - loss: 0.5973 - acc: 0.7910 - val_loss: 0.5586 - val_acc: 0.8101\n",
            "Epoch 70/70\n",
            "49/49 [==============================] - 35s 706ms/step - loss: 0.6001 - acc: 0.7885 - val_loss: 0.5684 - val_acc: 0.8087\n",
            "Saved trained model at /content/saved_models/keras_cifar10_trained_model.h5 \n",
            "10000/10000 [==============================] - 4s 377us/step\n",
            "Test loss: 0.5683807537078858\n",
            "Test accuracy: 0.8087\n",
            "50000/50000 [==============================] - 8s 165us/step\n",
            "Train loss: 0.407623036365509\n",
            "Train accuracy: 0.85738\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ehxDJSpPOhot",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "3e6bb574-5000-460d-93ae-e069ea582358"
      },
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "def convertCIFER10Data(image):\n",
        "    img = image.astype('float32')\n",
        "    img /= 255\n",
        "    c = np.zeros(32*32*3).reshape((1,32,32,3))\n",
        "    c[0] = img\n",
        "    return c\n",
        "  \n",
        "right = 0\n",
        "mistake = 0\n",
        "for i in range(100):\n",
        "    index = random.randint(0, x_test.shape[0])\n",
        "    image = x_test[index]\n",
        "    data = convertCIFER10Data(image)\n",
        "\n",
        "    ret = model.predict(data, batch_size=1) \n",
        "    #print(ret)\n",
        "\n",
        "    bestnum = 0.0\n",
        "    bestclass = 0\n",
        "    for n in [0,1,2,3,4,5,6,7,8,9]:\n",
        "        if bestnum < ret[0][n]:\n",
        "            bestnum = ret[0][n]\n",
        "            bestclass = n\n",
        "    i = list(y_test[index]).index(1)\n",
        "    if i == bestclass:\n",
        "      right += 1\n",
        "    else:\n",
        "      mistake += 1\n",
        "                                                                   \n",
        "\n",
        "print(\"The number of correct answers:\", right)\n",
        "print(\"The number of mistake:\", mistake)\n",
        "print(\"A correct answer rate:\", right/(mistake + right)*100, '%')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The number of correct answers: 16\n",
            "The number of mistake: 84\n",
            "A correct answer rate: 16.0 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "L0NuIQQjuN-A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "outputId": "a29a1a3b-b045-4bc8-cab8-8281063b87d0"
      },
      "cell_type": "code",
      "source": [
        "prn=model.predict(x_test)\n",
        "prn"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-8c90aea9a384>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "BOTEaaqllmd_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "sCP2KIRbbMBe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1853
        },
        "outputId": "574b08a2-663a-45e2-f91f-709083ea470a"
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "import os\n",
        "\n",
        "batch_size = 1024\n",
        "num_classes = 10\n",
        "epochs = 80\n",
        "data_augmentation = True\n",
        "num_predictions = 20\n",
        "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
        "model_name = 'keras_cifar10_trained_model.h5'\n",
        "\n",
        "# The data, split between train and test sets:\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# Convert class vectors to binary class matrices.\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), padding='same',\n",
        "                 input_shape=x_train.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "# initiate RMSprop optimizer\n",
        "#opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
        "opt = keras.optimizers.SGD(lr=0.0001, decay=1e-6)\n",
        "\n",
        "# Let's train the model using RMSprop\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "if not data_augmentation:\n",
        "    print('Not using data augmentation.')\n",
        "    model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True)\n",
        "else:\n",
        "    print('Using real-time data augmentation.')\n",
        "    # This will do preprocessing and realtime data augmentation:\n",
        "    datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
        "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        # randomly shift images horizontally (fraction of total width)\n",
        "        width_shift_range=0.1,\n",
        "        # randomly shift images vertically (fraction of total height)\n",
        "        height_shift_range=0.1,\n",
        "        shear_range=0.,  # set range for random shear\n",
        "        zoom_range=0.,  # set range for random zoom\n",
        "        channel_shift_range=0.,  # set range for random channel shifts\n",
        "        # set mode for filling points outside the input boundaries\n",
        "        fill_mode='nearest',\n",
        "        cval=0.,  # value used for fill_mode = \"constant\"\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=False,  # randomly flip images\n",
        "        # set rescaling factor (applied before any other transformation)\n",
        "        rescale=None,\n",
        "        # set function that will be applied on each input\n",
        "        preprocessing_function=None,\n",
        "        # image data format, either \"channels_first\" or \"channels_last\"\n",
        "        data_format=None,\n",
        "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
        "        validation_split=0.0)\n",
        "\n",
        "    # Compute quantities required for feature-wise normalization\n",
        "    # (std, mean, and principal components if ZCA whitening is applied).\n",
        "    datagen.fit(x_train)\n",
        "\n",
        "    # Fit the model on the batches generated by datagen.flow().\n",
        "    history=model.fit_generator(datagen.flow(x_train, y_train,\n",
        "                                     batch_size=batch_size),\n",
        "                        epochs=epochs,\n",
        "                        validation_data=(x_test, y_test),\n",
        "                        workers=4)\n",
        "    save_history(history, 'history.txt')\n",
        "\n",
        "# Save model and weights\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "model_path = os.path.join(save_dir, model_name)\n",
        "model.save(model_path)\n",
        "print('Saved trained model at %s ' % model_path)\n",
        "\n",
        "# Score trained model.\n",
        "scores = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n",
            "Using real-time data augmentation.\n",
            "Epoch 1/50\n",
            "49/49 [==============================] - 35s 720ms/step - loss: 2.3103 - acc: 0.0982 - val_loss: 2.3026 - val_acc: 0.0875\n",
            "Epoch 2/50\n",
            "49/49 [==============================] - 34s 700ms/step - loss: 2.3090 - acc: 0.0983 - val_loss: 2.3025 - val_acc: 0.0887\n",
            "Epoch 3/50\n",
            "49/49 [==============================] - 35s 705ms/step - loss: 2.3083 - acc: 0.0996 - val_loss: 2.3025 - val_acc: 0.0884\n",
            "Epoch 4/50\n",
            "49/49 [==============================] - 34s 702ms/step - loss: 2.3097 - acc: 0.0999 - val_loss: 2.3024 - val_acc: 0.0885\n",
            "Epoch 5/50\n",
            "49/49 [==============================] - 34s 702ms/step - loss: 2.3080 - acc: 0.1003 - val_loss: 2.3023 - val_acc: 0.0893\n",
            "Epoch 6/50\n",
            "49/49 [==============================] - 34s 700ms/step - loss: 2.3083 - acc: 0.0996 - val_loss: 2.3022 - val_acc: 0.0895\n",
            "Epoch 7/50\n",
            "49/49 [==============================] - 34s 698ms/step - loss: 2.3078 - acc: 0.1031 - val_loss: 2.3022 - val_acc: 0.0901\n",
            "Epoch 8/50\n",
            "49/49 [==============================] - 34s 703ms/step - loss: 2.3082 - acc: 0.1014 - val_loss: 2.3021 - val_acc: 0.0902\n",
            "Epoch 9/50\n",
            "49/49 [==============================] - 35s 708ms/step - loss: 2.3084 - acc: 0.0996 - val_loss: 2.3020 - val_acc: 0.0901\n",
            "Epoch 10/50\n",
            "49/49 [==============================] - 34s 693ms/step - loss: 2.3075 - acc: 0.1006 - val_loss: 2.3019 - val_acc: 0.0908\n",
            "Epoch 11/50\n",
            "49/49 [==============================] - 34s 694ms/step - loss: 2.3089 - acc: 0.0991 - val_loss: 2.3019 - val_acc: 0.0912\n",
            "Epoch 12/50\n",
            "49/49 [==============================] - 34s 692ms/step - loss: 2.3078 - acc: 0.1011 - val_loss: 2.3018 - val_acc: 0.0914\n",
            "Epoch 13/50\n",
            "49/49 [==============================] - 34s 691ms/step - loss: 2.3067 - acc: 0.1000 - val_loss: 2.3017 - val_acc: 0.0929\n",
            "Epoch 14/50\n",
            "49/49 [==============================] - 34s 688ms/step - loss: 2.3080 - acc: 0.1015 - val_loss: 2.3017 - val_acc: 0.0940\n",
            "Epoch 15/50\n",
            "49/49 [==============================] - 34s 696ms/step - loss: 2.3077 - acc: 0.0981 - val_loss: 2.3016 - val_acc: 0.0955\n",
            "Epoch 16/50\n",
            "49/49 [==============================] - 34s 694ms/step - loss: 2.3069 - acc: 0.0988 - val_loss: 2.3015 - val_acc: 0.0967\n",
            "Epoch 17/50\n",
            "49/49 [==============================] - 34s 691ms/step - loss: 2.3064 - acc: 0.1022 - val_loss: 2.3015 - val_acc: 0.0970\n",
            "Epoch 18/50\n",
            "49/49 [==============================] - 35s 705ms/step - loss: 2.3063 - acc: 0.0993 - val_loss: 2.3014 - val_acc: 0.0980\n",
            "Epoch 19/50\n",
            "49/49 [==============================] - 34s 698ms/step - loss: 2.3062 - acc: 0.1019 - val_loss: 2.3013 - val_acc: 0.0976\n",
            "Epoch 20/50\n",
            "49/49 [==============================] - 34s 693ms/step - loss: 2.3069 - acc: 0.0997 - val_loss: 2.3013 - val_acc: 0.0984\n",
            "Epoch 21/50\n",
            "49/49 [==============================] - 34s 699ms/step - loss: 2.3061 - acc: 0.1007 - val_loss: 2.3012 - val_acc: 0.0990\n",
            "Epoch 22/50\n",
            "49/49 [==============================] - 34s 696ms/step - loss: 2.3070 - acc: 0.0997 - val_loss: 2.3012 - val_acc: 0.0993\n",
            "Epoch 23/50\n",
            "49/49 [==============================] - 34s 696ms/step - loss: 2.3048 - acc: 0.1038 - val_loss: 2.3011 - val_acc: 0.0998\n",
            "Epoch 24/50\n",
            "49/49 [==============================] - 34s 697ms/step - loss: 2.3066 - acc: 0.0983 - val_loss: 2.3010 - val_acc: 0.1008\n",
            "Epoch 25/50\n",
            "49/49 [==============================] - 34s 698ms/step - loss: 2.3065 - acc: 0.1039 - val_loss: 2.3010 - val_acc: 0.1016\n",
            "Epoch 26/50\n",
            "49/49 [==============================] - 34s 701ms/step - loss: 2.3052 - acc: 0.1013 - val_loss: 2.3009 - val_acc: 0.1013\n",
            "Epoch 27/50\n",
            "49/49 [==============================] - 34s 701ms/step - loss: 2.3055 - acc: 0.1004 - val_loss: 2.3009 - val_acc: 0.1016\n",
            "Epoch 28/50\n",
            "49/49 [==============================] - 34s 691ms/step - loss: 2.3055 - acc: 0.1006 - val_loss: 2.3008 - val_acc: 0.1031\n",
            "Epoch 29/50\n",
            "49/49 [==============================] - 34s 693ms/step - loss: 2.3063 - acc: 0.0990 - val_loss: 2.3008 - val_acc: 0.1060\n",
            "Epoch 30/50\n",
            "49/49 [==============================] - 34s 700ms/step - loss: 2.3063 - acc: 0.1005 - val_loss: 2.3007 - val_acc: 0.1063\n",
            "Epoch 31/50\n",
            "49/49 [==============================] - 34s 699ms/step - loss: 2.3054 - acc: 0.1027 - val_loss: 2.3007 - val_acc: 0.1073\n",
            "Epoch 32/50\n",
            "49/49 [==============================] - 34s 698ms/step - loss: 2.3062 - acc: 0.0992 - val_loss: 2.3006 - val_acc: 0.1074\n",
            "Epoch 33/50\n",
            "49/49 [==============================] - 34s 696ms/step - loss: 2.3050 - acc: 0.1026 - val_loss: 2.3006 - val_acc: 0.1077\n",
            "Epoch 34/50\n",
            "49/49 [==============================] - 34s 696ms/step - loss: 2.3048 - acc: 0.1007 - val_loss: 2.3005 - val_acc: 0.1080\n",
            "Epoch 35/50\n",
            "49/49 [==============================] - 34s 693ms/step - loss: 2.3050 - acc: 0.1008 - val_loss: 2.3005 - val_acc: 0.1078\n",
            "Epoch 36/50\n",
            "49/49 [==============================] - 34s 690ms/step - loss: 2.3050 - acc: 0.1005 - val_loss: 2.3004 - val_acc: 0.1085\n",
            "Epoch 37/50\n",
            "49/49 [==============================] - 35s 706ms/step - loss: 2.3053 - acc: 0.1003 - val_loss: 2.3004 - val_acc: 0.1090\n",
            "Epoch 38/50\n",
            "49/49 [==============================] - 34s 692ms/step - loss: 2.3050 - acc: 0.1029 - val_loss: 2.3003 - val_acc: 0.1082\n",
            "Epoch 39/50\n",
            "49/49 [==============================] - 34s 700ms/step - loss: 2.3044 - acc: 0.1040 - val_loss: 2.3003 - val_acc: 0.1076\n",
            "Epoch 40/50\n",
            "49/49 [==============================] - 34s 685ms/step - loss: 2.3050 - acc: 0.1010 - val_loss: 2.3002 - val_acc: 0.1077\n",
            "Epoch 41/50\n",
            "49/49 [==============================] - 34s 689ms/step - loss: 2.3036 - acc: 0.1010 - val_loss: 2.3002 - val_acc: 0.1080\n",
            "Epoch 42/50\n",
            "49/49 [==============================] - 34s 694ms/step - loss: 2.3049 - acc: 0.1002 - val_loss: 2.3001 - val_acc: 0.1079\n",
            "Epoch 43/50\n",
            "49/49 [==============================] - 34s 695ms/step - loss: 2.3045 - acc: 0.1035 - val_loss: 2.3001 - val_acc: 0.1084\n",
            "Epoch 44/50\n",
            "49/49 [==============================] - 34s 694ms/step - loss: 2.3035 - acc: 0.1035 - val_loss: 2.3000 - val_acc: 0.1085\n",
            "Epoch 45/50\n",
            "49/49 [==============================] - 34s 697ms/step - loss: 2.3045 - acc: 0.1015 - val_loss: 2.3000 - val_acc: 0.1087\n",
            "Epoch 46/50\n",
            "49/49 [==============================] - 35s 709ms/step - loss: 2.3038 - acc: 0.1030 - val_loss: 2.2999 - val_acc: 0.1100\n",
            "Epoch 47/50\n",
            "49/49 [==============================] - 34s 700ms/step - loss: 2.3039 - acc: 0.1036 - val_loss: 2.2999 - val_acc: 0.1102\n",
            "Epoch 48/50\n",
            "49/49 [==============================] - 34s 701ms/step - loss: 2.3035 - acc: 0.1037 - val_loss: 2.2998 - val_acc: 0.1098\n",
            "Epoch 49/50\n",
            "49/49 [==============================] - 34s 702ms/step - loss: 2.3040 - acc: 0.1002 - val_loss: 2.2998 - val_acc: 0.1098\n",
            "Epoch 50/50\n",
            "49/49 [==============================] - 34s 701ms/step - loss: 2.3030 - acc: 0.1026 - val_loss: 2.2997 - val_acc: 0.1091\n",
            "Saved trained model at /content/saved_models/keras_cifar10_trained_model.h5 \n",
            "10000/10000 [==============================] - 4s 357us/step\n",
            "Test loss: 2.299719409561157\n",
            "Test accuracy: 0.1091\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eYXR2W7atItb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1921
        },
        "outputId": "6b21eb34-77b2-4a77-a9fe-f324fe0e0ab4"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "import os\n",
        "\n",
        "\n",
        "batch_size = 1024\n",
        "num_classes = 10\n",
        "epochs = 80\n",
        "data_augmentation = True\n",
        "num_predictions = 20\n",
        "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
        "model_name = 'keras_cifar10_trained_model.h5'\n",
        "\n",
        "# The data, split between train and test sets:\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# Convert class vectors to binary class matrices.\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), padding='same',\n",
        "                 input_shape=x_train.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "# initiate RMSprop optimizer\n",
        "opt = keras.optimizers.adagrad(lr=0.001, decay=1e-6)\n",
        "\n",
        "# Let's train the model using RMSprop\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "if not data_augmentation:\n",
        "    print('Not using data augmentation.')\n",
        "    model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True)\n",
        "else:\n",
        "    print('Using real-time data augmentation.')\n",
        "    # This will do preprocessing and realtime data augmentation:\n",
        "    datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
        "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        # randomly shift images horizontally (fraction of total width)\n",
        "        width_shift_range=0.1,\n",
        "        # randomly shift images vertically (fraction of total height)\n",
        "        height_shift_range=0.1,\n",
        "        shear_range=0.,  # set range for random shear\n",
        "        zoom_range=0.,  # set range for random zoom\n",
        "        channel_shift_range=0.,  # set range for random channel shifts\n",
        "        # set mode for filling points outside the input boundaries\n",
        "        fill_mode='nearest',\n",
        "        cval=0.,  # value used for fill_mode = \"constant\"\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=False,  # randomly flip images\n",
        "        # set rescaling factor (applied before any other transformation)\n",
        "        rescale=None,\n",
        "        # set function that will be applied on each input\n",
        "        preprocessing_function=None,\n",
        "        # image data format, either \"channels_first\" or \"channels_last\"\n",
        "        data_format=None,\n",
        "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
        "        validation_split=0.0)\n",
        "\n",
        "    # Compute quantities required for feature-wise normalization\n",
        "    # (std, mean, and principal components if ZCA whitening is applied).\n",
        "    datagen.fit(x_train)\n",
        "\n",
        "    # Fit the model on the batches generated by datagen.flow().\n",
        "    history =model.fit_generator(datagen.flow(x_train, y_train,\n",
        "                                     batch_size=batch_size),\n",
        "                        epochs=epochs,\n",
        "                        validation_data=(x_test, y_test),\n",
        "                        workers=4)\n",
        "    save_history(history, 'history.txt')\n",
        "\n",
        "# Save model and weights\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "model_path = os.path.join(save_dir, model_name)\n",
        "model.save(model_path)\n",
        "print('Saved trained model at %s ' % model_path)\n",
        "\n",
        "# Score trained model.\n",
        "scores = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])\n",
        "scores_train = model.evaluate(x_train, y_train, verbose=1)\n",
        "print('Train loss:', scores_train[0])\n",
        "print('Train accuracy:', scores_train[1])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n",
            "Using real-time data augmentation.\n",
            "WARNING:tensorflow:Variable *= will be deprecated. Use `var.assign(var * other)` if you want assignment to the variable value or `x = x * y` if you want a new python Tensor object.\n",
            "Epoch 1/50\n",
            "49/49 [==============================] - 36s 725ms/step - loss: 2.0747 - acc: 0.2369 - val_loss: 1.8504 - val_acc: 0.3494\n",
            "Epoch 2/50\n",
            "49/49 [==============================] - 35s 704ms/step - loss: 1.8519 - acc: 0.3279 - val_loss: 1.7297 - val_acc: 0.3876\n",
            "Epoch 3/50\n",
            "49/49 [==============================] - 34s 693ms/step - loss: 1.7832 - acc: 0.3554 - val_loss: 1.6807 - val_acc: 0.3983\n",
            "Epoch 4/50\n",
            "49/49 [==============================] - 34s 693ms/step - loss: 1.7411 - acc: 0.3664 - val_loss: 1.6388 - val_acc: 0.4145\n",
            "Epoch 5/50\n",
            "49/49 [==============================] - 35s 705ms/step - loss: 1.7050 - acc: 0.3797 - val_loss: 1.6460 - val_acc: 0.4091\n",
            "Epoch 6/50\n",
            "49/49 [==============================] - 35s 706ms/step - loss: 1.6809 - acc: 0.3873 - val_loss: 1.6281 - val_acc: 0.4182\n",
            "Epoch 7/50\n",
            "49/49 [==============================] - 34s 703ms/step - loss: 1.6575 - acc: 0.3934 - val_loss: 1.5933 - val_acc: 0.4291\n",
            "Epoch 8/50\n",
            "49/49 [==============================] - 35s 711ms/step - loss: 1.6375 - acc: 0.4023 - val_loss: 1.5237 - val_acc: 0.4517\n",
            "Epoch 9/50\n",
            "49/49 [==============================] - 35s 708ms/step - loss: 1.6216 - acc: 0.4073 - val_loss: 1.5812 - val_acc: 0.4369\n",
            "Epoch 10/50\n",
            "49/49 [==============================] - 35s 709ms/step - loss: 1.6027 - acc: 0.4127 - val_loss: 1.4845 - val_acc: 0.4645\n",
            "Epoch 11/50\n",
            "49/49 [==============================] - 35s 721ms/step - loss: 1.5800 - acc: 0.4222 - val_loss: 1.4912 - val_acc: 0.4571\n",
            "Epoch 12/50\n",
            "49/49 [==============================] - 35s 708ms/step - loss: 1.5741 - acc: 0.4235 - val_loss: 1.5002 - val_acc: 0.4582\n",
            "Epoch 13/50\n",
            "49/49 [==============================] - 34s 694ms/step - loss: 1.5596 - acc: 0.4278 - val_loss: 1.4654 - val_acc: 0.4683\n",
            "Epoch 14/50\n",
            "49/49 [==============================] - 35s 709ms/step - loss: 1.5497 - acc: 0.4323 - val_loss: 1.4586 - val_acc: 0.4736\n",
            "Epoch 15/50\n",
            "49/49 [==============================] - 35s 705ms/step - loss: 1.5364 - acc: 0.4381 - val_loss: 1.4408 - val_acc: 0.4773\n",
            "Epoch 16/50\n",
            "49/49 [==============================] - 34s 696ms/step - loss: 1.5342 - acc: 0.4393 - val_loss: 1.4171 - val_acc: 0.4821\n",
            "Epoch 17/50\n",
            "49/49 [==============================] - 35s 709ms/step - loss: 1.5230 - acc: 0.4461 - val_loss: 1.4234 - val_acc: 0.4825\n",
            "Epoch 18/50\n",
            "49/49 [==============================] - 35s 711ms/step - loss: 1.5149 - acc: 0.4491 - val_loss: 1.4889 - val_acc: 0.4609\n",
            "Epoch 19/50\n",
            "49/49 [==============================] - 35s 713ms/step - loss: 1.5133 - acc: 0.4482 - val_loss: 1.4222 - val_acc: 0.4818\n",
            "Epoch 20/50\n",
            "49/49 [==============================] - 35s 710ms/step - loss: 1.5043 - acc: 0.4529 - val_loss: 1.3953 - val_acc: 0.4958\n",
            "Epoch 21/50\n",
            "49/49 [==============================] - 35s 710ms/step - loss: 1.5024 - acc: 0.4532 - val_loss: 1.4089 - val_acc: 0.4893\n",
            "Epoch 22/50\n",
            "49/49 [==============================] - 34s 698ms/step - loss: 1.4931 - acc: 0.4574 - val_loss: 1.3777 - val_acc: 0.5016\n",
            "Epoch 23/50\n",
            "49/49 [==============================] - 34s 698ms/step - loss: 1.4854 - acc: 0.4576 - val_loss: 1.3875 - val_acc: 0.4952\n",
            "Epoch 24/50\n",
            "49/49 [==============================] - 35s 710ms/step - loss: 1.4846 - acc: 0.4596 - val_loss: 1.3889 - val_acc: 0.4978\n",
            "Epoch 25/50\n",
            "49/49 [==============================] - 35s 711ms/step - loss: 1.4801 - acc: 0.4604 - val_loss: 1.3996 - val_acc: 0.4909\n",
            "Epoch 26/50\n",
            "49/49 [==============================] - 35s 706ms/step - loss: 1.4718 - acc: 0.4643 - val_loss: 1.4054 - val_acc: 0.4898\n",
            "Epoch 27/50\n",
            "49/49 [==============================] - 35s 710ms/step - loss: 1.4697 - acc: 0.4658 - val_loss: 1.3689 - val_acc: 0.5034\n",
            "Epoch 28/50\n",
            "49/49 [==============================] - 36s 730ms/step - loss: 1.4649 - acc: 0.4688 - val_loss: 1.3750 - val_acc: 0.5025\n",
            "Epoch 29/50\n",
            "49/49 [==============================] - 34s 696ms/step - loss: 1.4649 - acc: 0.4668 - val_loss: 1.3962 - val_acc: 0.4925\n",
            "Epoch 30/50\n",
            "49/49 [==============================] - 35s 709ms/step - loss: 1.4593 - acc: 0.4695 - val_loss: 1.3641 - val_acc: 0.5091\n",
            "Epoch 31/50\n",
            "49/49 [==============================] - 35s 706ms/step - loss: 1.4524 - acc: 0.4716 - val_loss: 1.3578 - val_acc: 0.5111\n",
            "Epoch 32/50\n",
            "49/49 [==============================] - 34s 702ms/step - loss: 1.4472 - acc: 0.4763 - val_loss: 1.3531 - val_acc: 0.5115\n",
            "Epoch 33/50\n",
            "49/49 [==============================] - 35s 705ms/step - loss: 1.4500 - acc: 0.4758 - val_loss: 1.3443 - val_acc: 0.5150\n",
            "Epoch 34/50\n",
            "49/49 [==============================] - 35s 705ms/step - loss: 1.4410 - acc: 0.4772 - val_loss: 1.3364 - val_acc: 0.5168\n",
            "Epoch 35/50\n",
            "49/49 [==============================] - 34s 702ms/step - loss: 1.4389 - acc: 0.4790 - val_loss: 1.3363 - val_acc: 0.5182\n",
            "Epoch 36/50\n",
            "49/49 [==============================] - 34s 699ms/step - loss: 1.4360 - acc: 0.4789 - val_loss: 1.3298 - val_acc: 0.5231\n",
            "Epoch 37/50\n",
            "49/49 [==============================] - 35s 717ms/step - loss: 1.4330 - acc: 0.4813 - val_loss: 1.3238 - val_acc: 0.5259\n",
            "Epoch 38/50\n",
            "49/49 [==============================] - 34s 703ms/step - loss: 1.4261 - acc: 0.4845 - val_loss: 1.3440 - val_acc: 0.5159\n",
            "Epoch 39/50\n",
            "49/49 [==============================] - 34s 696ms/step - loss: 1.4244 - acc: 0.4859 - val_loss: 1.3618 - val_acc: 0.5082\n",
            "Epoch 40/50\n",
            "49/49 [==============================] - 35s 707ms/step - loss: 1.4271 - acc: 0.4838 - val_loss: 1.3419 - val_acc: 0.5139\n",
            "Epoch 41/50\n",
            "49/49 [==============================] - 35s 708ms/step - loss: 1.4241 - acc: 0.4877 - val_loss: 1.3091 - val_acc: 0.5292\n",
            "Epoch 42/50\n",
            "49/49 [==============================] - 34s 700ms/step - loss: 1.4178 - acc: 0.4888 - val_loss: 1.3290 - val_acc: 0.5226\n",
            "Epoch 43/50\n",
            "49/49 [==============================] - 35s 707ms/step - loss: 1.4134 - acc: 0.4891 - val_loss: 1.3309 - val_acc: 0.5198\n",
            "Epoch 44/50\n",
            "49/49 [==============================] - 35s 713ms/step - loss: 1.4115 - acc: 0.4929 - val_loss: 1.3153 - val_acc: 0.5266\n",
            "Epoch 45/50\n",
            "49/49 [==============================] - 34s 702ms/step - loss: 1.4113 - acc: 0.4943 - val_loss: 1.3249 - val_acc: 0.5233\n",
            "Epoch 46/50\n",
            "49/49 [==============================] - 35s 719ms/step - loss: 1.4058 - acc: 0.4939 - val_loss: 1.3116 - val_acc: 0.5285\n",
            "Epoch 47/50\n",
            "49/49 [==============================] - 34s 703ms/step - loss: 1.4015 - acc: 0.4941 - val_loss: 1.3165 - val_acc: 0.5265\n",
            "Epoch 48/50\n",
            "49/49 [==============================] - 35s 710ms/step - loss: 1.4012 - acc: 0.4926 - val_loss: 1.2999 - val_acc: 0.5339\n",
            "Epoch 49/50\n",
            "49/49 [==============================] - 35s 705ms/step - loss: 1.4015 - acc: 0.4943 - val_loss: 1.3258 - val_acc: 0.5218\n",
            "Epoch 50/50\n",
            "49/49 [==============================] - 35s 712ms/step - loss: 1.3942 - acc: 0.4978 - val_loss: 1.2985 - val_acc: 0.5324\n",
            "Saved trained model at /content/saved_models/keras_cifar10_trained_model.h5 \n",
            "10000/10000 [==============================] - 4s 391us/step\n",
            "Test loss: 1.2984622220993043\n",
            "Test accuracy: 0.5324\n",
            "50000/50000 [==============================] - 10s 198us/step\n",
            "Train loss: 1.2932057030868531\n",
            "Train accuracy: 0.5384\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2JdgVJVpOSNe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "1007dbe5-1c69-4290-88ac-e901ae5b7fab"
      },
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "def convertCIFER10Data(image):\n",
        "    img = image.astype('float32')\n",
        "    img /= 255\n",
        "    c = np.zeros(32*32*3).reshape((1,32,32,3))\n",
        "    c[0] = img\n",
        "    return c\n",
        "  \n",
        "right = 0\n",
        "mistake = 0\n",
        "for i in range(100):\n",
        "    index = random.randint(0, x_test.shape[0])\n",
        "    image = x_test[index]\n",
        "    data = convertCIFER10Data(image)\n",
        "\n",
        "    ret = model.predict(data, batch_size=1) \n",
        "    #print(ret)\n",
        "\n",
        "    bestnum = 0.0\n",
        "    bestclass = 0\n",
        "    for n in [0,1,2,3,4,5,6,7,8,9]:\n",
        "        if bestnum < ret[0][n]:\n",
        "            bestnum = ret[0][n]\n",
        "            bestclass = n\n",
        "    i = list(y_test[index]).index(1)\n",
        "    if i == bestclass:\n",
        "      right += 1\n",
        "    else:\n",
        "      mistake += 1\n",
        "                                                                   \n",
        "\n",
        "print(\"The number of correct answers:\", right)\n",
        "print(\"The number of mistake:\", mistake)\n",
        "print(\"A correct answer rate:\", right/(mistake + right)*100, '%')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The number of correct answers: 7\n",
            "The number of mistake: 93\n",
            "A correct answer rate: 7.000000000000001 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eH7BouLDOTKL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sZwFMq8a8I84",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 789
        },
        "outputId": "bfda67b0-8f6b-4cdd-b08b-4a85432bb34f"
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(0)\n",
        "plt.plot(history.history['acc'],'r')\n",
        "plt.plot(history.history['val_acc'],'g')\n",
        "#plt.xticks(np.arange(0, 101, 2.0))\n",
        "plt.rcParams['figure.figsize'] = (8, 6)\n",
        "plt.xlabel(\"Num of Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Training Accuracy vs Validation Accuracy\")\n",
        "plt.legend(['train','validation'])\n",
        "\n",
        "\n",
        "plt.figure(1)\n",
        "plt.plot(history.history['loss'],'r')\n",
        "plt.plot(history.history['val_loss'],'g')\n",
        "#plt.xticks(np.arange(0, 101, 2.0))\n",
        "plt.rcParams['figure.figsize'] = (8, 6)\n",
        "plt.xlabel(\"Num of Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Training Loss vs Validation Loss\")\n",
        "plt.legend(['train','validation'])\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfUAAAGCCAYAAAD5b1poAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlCkuVe4xCCMAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f6309ab31d0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAGCCAYAAADJ40tJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f630b1c2a20>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "fyU9TdA4-yuK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "7b721e14-e81f-4ba3-980a-eec661756cd2"
      },
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "def convertCIFER10Data(image):\n",
        "    img = image.astype('float32')\n",
        "    img /= 255\n",
        "    c = np.zeros(32*32*3).reshape((1,32,32,3))\n",
        "    c[0] = img\n",
        "    return c\n",
        "  \n",
        "right = 0\n",
        "mistake = 0\n",
        "for i in range(100):\n",
        "    index = random.randint(0, x_test.shape[0])\n",
        "    image = x_test[index]\n",
        "    data = convertCIFER10Data(image)\n",
        "\n",
        "    ret = model.predict(data, batch_size=1) \n",
        "    #print(ret)\n",
        "\n",
        "    bestnum = 0.0\n",
        "    bestclass = 0\n",
        "    for n in [0,1,2,3,4,5,6,7,8,9]:\n",
        "        if bestnum < ret[0][n]:\n",
        "            bestnum = ret[0][n]\n",
        "            bestclass = n\n",
        "    i = list(y_test[index]).index(1)\n",
        "    if i == bestclass:\n",
        "      right += 1\n",
        "    else:\n",
        "      mistake += 1\n",
        "                                                                   \n",
        "\n",
        "print(\"The number of correct answers:\", right)\n",
        "print(\"The number of mistake:\", mistake)\n",
        "print(\"A correct answer rate:\", right/(mistake + right)*100, '%')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The number of correct answers: 9\n",
            "The number of mistake: 91\n",
            "A correct answer rate: 9.0 %\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}